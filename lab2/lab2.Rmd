---
title: "Laboratório 2 - Métodos Baseados em Árvores e Florestas Aleatórias"
author: "ME905"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.width = 6,
  fig.height = 4,
  fig.align = 'center'
)

set.seed(282828)

# packages
library(rpart)
library(ggplot2)
library(dplyr)
library(patchwork)

# definindo tema global ggplot
theme_set(
  theme_bw() +
    theme(
      plot.title = element_text(hjust = 0.5)
    )
)
```



# 1. Leitura dos Dados
```{r, message=F}
# lendo dados
library(readr)
mnist <- read_csv('MNIST0178.csv')
mnist$y <- as.factor(mnist$y)
```



# 2. Visualização de Dígitos

## a)
```{r, fig.width=5.5, fig.height=3}
# funções de visualização de dados
converte_df <- function(vetor_covariaveis) {
  vetor_covariaveis <- as.vector(unlist(vetor_covariaveis))
  if(length(vetor_covariaveis) != 784){
    stop("Passe um vetor com 784 valores!")
  }
  
  pos_x <- rep(1:28, each = 28)
  pos_y <- rep(1:28, times = 28)
  data.frame(pos_x, pos_y, valor = vetor_covariaveis)
}

visnum <- function(df) {
  df %>% ggplot(aes(x = pos_y, y = pos_x, fill = valor)) +
    geom_tile() +
    scale_fill_gradient(low = 'white', high = 'black') +
    theme_void() +
    scale_y_reverse() +
    theme(legend.position = 'none')
}

# lendo números
n1 <- converte_df(mnist[1,-1])  # 0
n2 <- converte_df(mnist[3,-1])  # 1
n3 <- converte_df(mnist[6,-1])  # 7
n4 <- converte_df(mnist[7,-1])  # 8

# visualizando números
(visnum(n1) + visnum(n2)) / (visnum(n3) + visnum(n4))
```

Vemos os números 0 e 1 na parte superior e 7 e 8 na parte inferior.

## b)
Possívelmente, os números mais difíceis de serem distinguidos são os dígitos 1 e 7 pela sua semelhança e, analogamente, teremos menos dificuldade entre o 0 e o 8 com relação aos demais.



# 3. Árvore de Classificação com `rpart`

```{r ajustando_arvore}
fit <- rpart(y ~ ., data = mnist)     # ajustando modelo
pred <- predict(fit, type = 'class')  # categorias preditas

acuracia <- sum(pred == mnist$y)/length(mnist$y)
table('Predição' = pred, 'Valores Verdadeiros' = mnist$y)  # matriz de confusão
```

Houve uma acurácia de, aproximadamente, `r 100 * round(acuracia, 3)`%, então a árvore foi eficaz. Além disso, como nossas suspeitas, o 0 foi mais confundido com o 8. No entanto, não esperávamos que o 1 e o 7 fossem mais confundidos com o 8 e o 8 foi mais confundido com o 1.



# 4. Florestas Aleatórias (com Estratégias Manuais)
```{r}
# função: bs -------------------------------------------------------------------
# Executa o bootstrap.
# data banco de dados com a primeira coluna sendo a resposta.

bs <- function(data) {
  return(sample(1:nrow(data), nrow(data), replace = T))
}


# função: random_forest --------------------------------------------------------
# Gera floresta aleatória.
# data banco de dados.
# n_tree número de árvores.
# ... parâmetros para o ajuste da função `rpart`.

random_forest <- function(data, n_tree, p = NULL, ...) {
  controle <- rpart.control(...)  # controle de parâmetros do rpart
  
  # definindo objetos
  n <- nrow(data)  # número de observações
  p_tot <- ncol(data)
  classes <- c('0', '1', '7', '8')
  forest <- vector(mode = 'list', length = n_tree)  # armazenar as árvores
  if (is.null(p)) p <- round(sqrt(ncol(data)))        # sugestão apresentada em aula
  oob_pred <- data.frame(matrix(NA, nrow=n, ncol=n_tree,  # guarda predição por árvore
                            dimnames = list(NULL, paste0(rep('tree'), 1:n_tree))))
  
  for (t in 1:n_tree) {
    linhas_sorteadas <- bs(data)
    oob_indices <- setdiff(1:n, unique(linhas_sorteadas)) # linhas não sorteadas
    
    colunas_selecionadas <- c(1, sample(2:p_tot, p))  # y e preditoras selecionadas
    db_bs <- data[linhas_sorteadas, colunas_selecionadas]
    
    forest[[t]] <- rpart(y ~ ., db_bs, control = controle)  # ajustando arvore
    
    oob_data <- data[oob_indices, colunas_selecionadas]  # df de obs. não usadas
    pred <- predict(forest[[t]], newdata = oob_data, type = 'class')
    oob_pred[oob_indices,t] <- as.character(pred)
  }
  
  pred <- apply(oob_pred, 1, \(x) {  # voto da maioria
    table <- table(x)
    if (length(table) == 0) NA else names(which.max(table))
  })
  
  oob <- mean(pred != data$y, na.rm = T)  # erro out of bag do modelo
  oob_class_error <- data.frame(          # acurácia out of bag por classe
    classe_0 = mean(data$y[which(data$y == 0)] == pred[which(data$y == 0)], na.rm=T),
    classe_1 = mean(data$y[which(data$y == 1)] == pred[which(data$y == 1)], na.rm=T),
    classe_7 = mean(data$y[which(data$y == 7)] == pred[which(data$y == 7)], na.rm=T),
    classe_8 = mean(data$y[which(data$y == 8)] == pred[which(data$y == 8)], na.rm=T)
  )
  
  return(list(
    forest = forest,
    oob_class_error = oob_class_error,
    oob_accuracy = 1 - oob
  ))
}
```

Com a função `random_forest` definida vamos ajustar 9 modelos variando o número de árvores (`n_tree`), quantidade de preditoras disponíveis para o modelo (`p`) e tamanho máximo da árvore (`maxdepth`).
```{r simulacao_de_modelos}
# ajsutando modelos
modelos <- list(
  modelo1 = random_forest(mnist, n_tree = 5 , p = 10, maxdepth = 5),
  modelo2 = random_forest(mnist, n_tree = 5 , p = 10, maxdepth = 20),
  modelo3 = random_forest(mnist, n_tree = 10, p = 28, maxdepth = 5),
  modelo4 = random_forest(mnist, n_tree = 10, p = 28, maxdepth = 20),
  modelo5 = random_forest(mnist, n_tree = 15, p = 50, maxdepth = 5),
  modelo6 = random_forest(mnist, n_tree = 15, p = 50, maxdepth = 20),
  modelo7 = random_forest(mnist, n_tree = 50, p = 28, maxdepth = 20),
  modelo8 = random_forest(mnist, n_tree = 50, p = 50, maxdepth = 20),
  modelo9 = random_forest(mnist, n_tree = 100 , p = 28,cp = 0,minsplit = 2,minbucket = 1,maxdepth = 30)
)

# resultados
sapply(modelos, \(x) 
  round(unlist(c(oob_accuracy = x$oob_accuracy, x$oob_class_error)), 4)) |>
  knitr::kable()
```

A tabela apresentada contém as informações da acurácia out-of-bag (primeira linha) e para cada dígito em específico dos modelos ajustados. A acurácia out-of-bag verifica o desempenho do modelo analisando a classificação das árvores para observações não utilziadas em seu treino, ou seja, é o mesmo que subtrair de 1 o erro out-of-bag. Logo, uma estimativa da taxa de erro para observações nunca vistas pode ser obtida fazendo a subtração entre 1 e a acurácia out-of-bag.

Além disso, note que os modelos 7, 8 e 9 foram os melhores, justamente os que apresentam o maior número de árvores. Ainda analisando os modelos 7 e 8, observou-se que fixando outros hiperparâmetros, não houve melhora significativa no modelo aumentando a quantidade de preditoras por árvore, até piorando levemente. Os modelos 1 e 2 foram excepcionalmente ruins e são justamente os que apresentam o menor número de árvores. O melhor modelo foi o 9, onde as árvores individuais são de profundidade máxima. Então, o parâmetro que mais parece importar é o número de árvores (`n_tree`), sendo relevante também a falta de limitação nas árvores, buscando profundidade máxima.

Foi determinado que o modelo9 apresenta o melhor resultado, portanto ele será o escolhido para seguir o trabalho. Para este modelo, espera-se que a taxa de acerto para observações nunca vistas seja de, aproximadamente, `r 100 * round(modelos$modelo9$oob_accuracy, 3)`%, ou seja, estima-se que sua taxa de erro será `r 100*round(1 - modelos$modelo9$oob_accuracy, 3)`% para novas observações.

Além disso, também testamos outros valores para alguns hiperparâmetros, como `minbucket` e `cp`, porém os melhores resultados ocorrem com essas regularizações conjuntamente minímas (ou inexistentes), permitindo que as árvores individuais sobreajustem.

# 5. Análise dos Erros

```{r plot_dos_possiveis_casos}
# função: predict.forest -------------------------------------------------------
# forest precisa ser um objeto da saída da função `random_forest`.
# data banco de dados para predição.

predict.forest <- function(forest, data) {
  pred_tree <- vector(mode='list', length(forest$forest))
  
  for (i in seq_along(forest$forest)) {
    pred_tree[[i]] <- unname(predict(forest$forest[[i]], type = 'class',
                                     newdata = data))
  }
  voto <- data.frame(tree = unname(do.call(cbind.data.frame, pred_tree)))
  apply(voto, 1, \(x) names(which.max(table(unlist(x)))))
}

# fazendo predição e modificando `converte_df` ---------------------------------
pred_forest <- predict.forest(modelos$modelo9, mnist)
mnist_com_pred <- cbind('pred' = pred_forest, mnist)  # juntando dados com predição

# combinando casos
combinacoes <- data.frame()

for (y in c(0,1,7,8)) {
  for (pred in c(0,1,7,8)) {
    combinacoes <- bind_rows(combinacoes, data.frame(pred = pred,
            mnist[mnist_com_pred$y == y & mnist_com_pred$pred == pred,][1,]))
  }
}

# modificando converte_df
converte_df_mod <- function(data) {
  pos_x <- rep(1:28, each = 28)
  pos_y <- rep(1:28, times = 28)
  resultado <- data.frame()
  
  for (i in 1:16) {
    pred <- data$pred[i]
    y <- data$y[i]
    vetor_covariaveis <- as.vector(unlist(data[i,-c(1,2)]))
    resultado <- bind_rows(resultado, bind_cols(pred = pred, y = y,
                    data.frame(pos_x, pos_y, valor = vetor_covariaveis)))
  }
  
  return(resultado)
}

erro_long <- converte_df_mod(combinacoes)

# plot
visnum(erro_long) +
  facet_grid(rows = vars(pred), cols = vars(y), switch = 'y') +
  theme_bw(base_size = 13) +
  labs(x = 'Verdadeiro', y = 'Predito',
       title = 'Situações possíveis') +
  theme(plot.title = element_text(hjust = 0.5),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        panel.grid = element_blank(),
        legend.position = 'none')
```

Não foi identificado um padrão na forma que os erros ocorrem. Além disso, as observações aparentam pouca ambiguidade. Com excessão da posição (1,3) que é um sete mas parece um zero aberto na parte inferior e (4,3) que é um sete cortado, parecendo um 8, possivelmente sendo o que causa a confusão no modelo e da posição.



# 6. Predição em Novos Dados

```{r}
# lendo novos dados
mnist_teste <- read.csv('MNIST0178-teste.csv')

# predição para modelo9 (retornando ao tipo original para facilitar correção)
pred_mnist_teste <- as.numeric(predict.forest(modelos$modelo9, mnist_teste))

# guardando predição
write.csv(data.frame(predicao = pred_mnist_teste), file='l2-pred-J.csv')
```
