---
title: "Laboratório 1 - Validação Cruzada e Seleção de Variáveis"
author: "ME905"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# packages
require(glmnet)
require(readr)
require(dplyr)
```

# Instruções

- Esta atividade contém duas partes com o mesmo peso na avaliação.

- Junto do código em cada item, descreva em forma de texto o método sendo
utilizado e discuta os resultados.
Apresente equações se achar necessário.

- Apresente respostas completas e apresente gráficos se achar necessário.

- A menos quando especificado, evite utilizar funções "prontas" para tarefas
que podem ser feitas utilizando a sintaxe básica do R. Por exemplo, a
separação dos bancos de dados em treino e teste deve ser implementada
sem funções de pacotes.

# Parte 1 - Seleção de Variáveis

O conjunto de dados `l1d1.csv` contém informações de 300 variáveis
(`x001` a `x300`) e uma variável resposta `y` (contínua) para 5000 observações.
O objetivo dessa parte é apresentar um modelo de regressão linear
(perda quadrática) com algum subconjunto das 300 variáveis disponíveis.

  (1) Obtenha um conjunto de variáveis com efeito significativo na resposta
  com base em testes de hipóteses. Faça os ajustes necessários
  (escolha um dos métodos) para controlar o número de
  variáveis selecionadas.

Utilizando a correção de Bonferroni:

```{r}
# leitura banco de dados
db <- read_csv("l1d1.csv")
db_val <- read_csv("l1d1-val.csv")

model <- lm(y ~., data = db)

ajuste <- summary(model)
ajuste$coefficients[ajuste$coefficients[, 4] < 0.05/300, 4]

model_reajustado <- lm(y ~ ., data = db[c(1, which(ajuste$coefficients[,4] < 0.05/300))])
summary(model_reajustado)
```

  (2) Implemente o método *Forward Stepwise Regression* e obtenha o conjunto
  de variáveis que minimiza o erro de predição sob perda quadrática para
  um conjunto de dados de teste.
  
```{r}
# data - banco de dados
# p_max - quantidade de preditoras máxima no último modelo ajustado

fsr <- function(data, p_max = 40) {
  # objetos
  pred_selecionado <- character(p_max)   # vetor com o nome dos pred selecionados
  EQM_teste <- numeric(p_max)            # salvar EQM minimo por iteração
  
  # separando banco de dados em 80/20
  n_treino <- 0.8 * nrow(data)      # 4000
  n_teste <- 0.2 * nrow(data)       # 1000
  shuffle <- sample(rep(c(1,2), times = c(n_treino, n_teste)))
  df_treino <- data[shuffle == 1,]  # 1 = treino
  df_teste <- data[shuffle == 2,]   # 2 = teste
  names_pred_all <- names(data[-1])     # nome de todas as preditoras
  
  for (p in 1:p_max) {
    names_pred <- setdiff(names_pred_all, pred_selecionado)  # preditores não selecionados
    EQM_treino <- vector(mode='numeric', length(names_pred))
    j <- 1
    
    for (i in names_pred) {  # iterando nos preditores não selecionados
      formula <- formula(paste('y ~', paste(c(pred_selecionado[1:p], i),
                                            collapse = ' + ')))
      EQM_treino[j] <- mean(lm(formula, df_treino)$residuals^2)
      j <- j + 1
    }
    
    pred_selecionado[p] <- names_pred[which.min(EQM_treino)]
    best_fit <- lm(y ~ ., df_treino[c('y', pred_selecionado[1:p])])
    EQM_teste[p] <- sum((df_teste$y - predict(best_fit, newdata = df_teste))^2)/n_teste
  }
  
  result <- data.frame(p = 1:p_max, EQM = EQM_teste, pred = pred_selecionado)
  return(list('preditores' = pred_selecionado, 'result' = result))
}

set.seed(282829)
obj <- fsr(db, p_max = 5)

knitr::kable(obj$result)
plot(obj$result$p, obj$result$EQM, xlab = 'p', ylab = 'EQM', type = 'b')
```

```{r, echo=F, eval=F}
# Verificação manual da função fsr
set.seed(282829)
n_treino <- 0.8 * nrow(db)   # 4000
n_teste <- 0.2 * nrow(db)    # 1000
shuffle <- sample(rep(c(1,2), times = c(n_treino, n_teste)))
treino <- db[shuffle == 1,]  # 1 = treino
teste <- db[shuffle == 2,]   # 2 = teste

# i = 1
EQM_1 <- numeric(300)
j <- 1
for (i in names(db[-1])) {
  formula <- formula(paste(c('y ~', i), collapse = ' + '))
  EQM_1[j] <- sum(lm(formula, treino)$residuals^2)/n_treino
  j <- j + 1
}
names(db[-1])[which.min(EQM_1)]  # x236


# i = 2
EQM_2 <- numeric(299)
j <- 1
for (i in names(db[-1])) {
  if (i == 'x236') next
  formula <- formula(paste(c('y ~ x236', i), collapse = ' + '))
  EQM_2[j] <- sum(lm(formula, treino)$residuals^2)/n_treino
  j <- j + 1
}
names(db[-c(1, which(names(db) %in% c('x236')))])[which.min(EQM_2)]  # x212

# i = 3
EQM_3 <- numeric(298)
j <- 1
for (i in names(db[-1])) {
  if (i %in% c('x236', 'x212')) next
  formula <- formula(paste(c('y ~ x236 + x212', i), collapse = ' + '))
  EQM_3[j] <- sum(lm(formula, treino)$residuals^2)/n_treino
  j <- j + 1
}
names(db[-c(1, which(names(db) %in% c('x236', 'x212')))])[which.min(EQM_3)]  # x226
```



  (3) Refaça o item 2 utilizando o método de validação cruzada k-fold, com k = 5.
  
```{r}
# cross_validation <- function(data, k = 5){
#   n <- nrow(data)
#   p <- ncol(data)
#  
#   shuffle <- sample(rep(1:k, n/k))
#   EQM <- numeric(k)
#  
#   for(i in 1:k) {
#     teste <- data[shuffle == i,]
#     treino <- data[shuffle != i,]
#    
#     modelo <- lm(y ~ ., treino)
#     pred <- predict(modelo, teste[,-1])
#    
#     EQM[i] <- (treino[1] - pred)^2/(n - p)
#   }
#  
#   cv_EQM <- mean(EQM)
#   return(list(cv_EQM, EQM))
# }


# data - banco de dados
# p_max - quantidade de preditoras máxima no último modelo ajustado
# k - quantidade de folds

fsr_cv <- function(data, p_max = 40, k = 5) {
  # objetos
  pred_selecionado <- character(p_max)  # vetor com o nome dos pred selecionados
  names_pred_all <- names(data[-1])     # nome de todas as preditoras
  result <- data.frame(
    p = 1:p_max,
    preditor = character(p_max),
    fold = integer(p_max),
    EQM_treino = numeric(p_max),
    EQM_teste = numeric(p_max)
  )
  
  # separação do banco de dados
  n <- nrow(data)
  shuffle <- sample(1:k, size = n, replace = T)
  
  for (p in 1:p_max) {
    names_pred <- setdiff(names_pred_all, pred_selecionado)  # preditores não selecionados
    j <- 1
    result_parcial <- data.frame(
      preditor = character(length(names_pred) * k),
      fold = integer(length(names_pred) * k),
      EQM_treino = numeric(length(names_pred) * k),
      EQM_teste = numeric(length(names_pred) * k)
    )

    for (i in names_pred) {  # iterando nos preditores não selecionados
      for (fold in 1:k) {  # iterando no k-ésimo fold
        df_treino <- data[shuffle != fold,]
        df_teste <- data[shuffle == fold,]
        formula <- formula(paste('y ~', paste(c(pred_selecionado[1:p], i),
                                              collapse = ' + ')))
        fit <- lm(formula, data = df_treino)
        
        result_parcial[j,] <-  data.frame(
          preditor = i, fold = fold, EQM_treino = mean(fit$residuals^2),
          EQM_teste = mean((df_teste$y - predict(fit, newdata = df_teste))^2)
        )
        j <- j + 1
        # result[j,] <-  data.frame(
        #   p = p, fold = fold, EQM_treino = mean(fit$residuals^2),
        #   EQM_teste = mean((df_teste$y - predict(fit, newdata = df_teste))^2),
        #   preditor = i
        # )
      }
    }
    
    estat_result <- result_parcial |>
      group_by(preditor) |>
      summarise_all(mean) |>
      select(-fold)
    pred_selecionado[p] <- estat_result$preditor[which.min(estat_result$EQM_treino)]
    result[p,-1] <- estat_result[which.min(estat_result$EQM_treino),]
  }
  
  return(result)
}

a <- fsr_cv(db, p_max = 2)
```
  
```{r, eval=F, echo=F}
# testes, reproduzindo o que foi feito no slide
set.seed(2)
n <- 5000
X <- runif(n, min = 0, max = 100)
f <- function(x){
  150 + 10*cos(x/15)
}
y <- rnorm(n, mean = f(X), sd = 3)
df <- data.frame(x = X, y = y)

set.seed(1)
K <- 10
folds <- sample(1:K, size = n, replace = TRUE)

resultados_kfold <- data.frame(
  fold = integer(0),
  grau = integer(0),
  EQM_treino = numeric(0),
  EQM_teste = numeric(0)
)

for(grau in 1:25) {
  for(fold in 1:K) {
    df_treino <- df[!folds == fold,]
    df_teste <- df[folds == fold,]
    ajuste <- lm(y ~ poly(x, grau), data = df_treino)
    predicoes <- predict(ajuste, df_teste)
    resultados_kfold <- rbind(resultados_kfold,
                              data.frame(fold = fold, grau = grau,
                                         EQM_treino = mean(ajuste$residuals^2),
                                         EQM_teste = mean((df_teste$y - predicoes)^2)))
  }
}

resultados_kfold |> head()

resumo <- resultados_kfold |>
group_by(grau) |>
summarise_all(mean) |>
select(-fold)

resumo$grau[which.min(resumo$EQM_teste)]
```
  
  
  (4) Com base nos métodos discutidos e nos resultados obtidos, qual subconjunto das 300 variáveis você diria que possuem um efeito não nulo na resposta $y$?
  
# Parte 2 - LASSO

Para essa parte, utilize a função `glmnet` do pacote `glmnet` para realizar ajustes utilizando o método LASSO.

  (1) Leia a documentação da função `glmnet` e a vignette disponível em https://glmnet.stanford.edu/articles/glmnet.html. Descreva os principais parâmetros da função que serão necessários para ajustar um modelo baseado em LASSO para um determinado conjunto de dados.

x: matriz de input de dimensão $n \times p$. Necessário que $p \geq 2$.

y: variável resposta. o parâmetro `family` pode ser usado para especificar se a variável é quantitativa, de contagem, entre outros.

alpha: faz uma "mistura" entre Lasso (`alpha = 1`) e Ridge (`alpha = 0`).

  
  (2) Separe 10% do seu conjunto de dados como um conjunto de dados de teste. Com os 90% restante (conjunto de treino), ajuste uma regressão com LASSO considerando $\lambda = 2$. Calcule o Erro Quadrático Médio de predição para o conjunto de treino e o conjunto de teste. Quantas variáveis tiveram coeficientes não nulos para este ajuste?
  
```{r}
# separando dados
# 0.9 * nrow(db)  # 90% = 4500 linhas
# 0.1 * nrow(db)  # 10% =  500 linhas
#set.seed(123)
shuffle <- sample(rep(c(1,2), times = c(4500, 500)))
treino <- db[shuffle == 1,]
teste <- db[shuffle == 2,]

# ajustando modelo
modelasso <- glmnet(x = as.matrix(treino[,-1]), y = as.matrix(treino[,1]), alpha = 1, lambda = 2)

# predições
pred_treino <- predict(modelasso, newx = as.matrix(treino[,-1]), s = 2)
pred_teste <- predict(modelasso, newx = as.matrix(teste[,-1]), s = 2)

# EQM
eqm_treino <- mean((as.matrix(treino[,1]) - pred_treino)^2)
eqm_teste <- mean((as.matrix(teste[,1]) - pred_teste)^2)
eqm_treino
eqm_teste

# quantidade de variáveis com coeficientes não nulos
sum(coef(modelasso) != 0)
```
  
  
  (3) Escolha (pelo menos) 10 valores de $\lambda$. Para cada valor de $\lambda$, refaça o item (2), com os mesmos conjuntos de treino/teste. Compare os erros de predição no teste para cada valor de $\lambda$. Qual valor de $\lambda$ produziu o menor erro de predição?
  
```{r}
lambda <- c(0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.75, 1, 1.5, 3)
pred_treino_grid <- matrix(0, nrow = nrow(treino), ncol = length(lambda))
pred_teste_grid <- matrix(0, nrow = nrow(teste), ncol = length(lambda)) 
eqm_treino_grid <- numeric(10)
eqm_teste_grid <- numeric(10)   

for (i in 1:length(lambda)){
  fit <-  glmnet(x = as.matrix(treino[,-1]), y = as.matrix(treino[,1]), alpha = 1, lambda = lambda[i])
  pred_treino_grid[,i] <- predict(fit, newx = as.matrix(treino[,-1]), s = lambda[i])
  pred_teste_grid[,i] <- predict(fit, newx = as.matrix(teste[,-1]), s = lambda[i])

  eqm_treino_grid[i] <- mean((as.matrix(treino[,1]) - pred_treino_grid[,i])^2)
  eqm_teste_grid[i] <- mean((as.matrix(teste[,1]) - pred_teste_grid[,i])^2)
}
  grid <- cbind(eqm_treino_grid, eqm_teste_grid, lambda)
  min_eqm_lambda_treino <- lambda[which.min(eqm_treino_grid)]
  min_eqm_lambda_teste <- lambda[which.min(eqm_teste_grid)]
  min_eqm_lambda_treino
  min_eqm_lambda_teste
```


  (4) Considere os dados no arquivo `l1d1-val.csv`. Este conjunto de dados não possui o valor da variável resposta. Gere um arquivo chamada `l1-pred-[grupo].csv` contendo as predições para as 1000 observações disponíveis no arquivo, com base no ajuste que você considera mais apropriado para fazer predições. Substitua `[grupo]` pela letra associada ao grupo no Moodle.
  
```{r}
db_final <- read_csv("l1d1-val.csv")

best_modelasso <- glmnet(x = as.matrix(treino[,-1]), y = as.matrix(treino[,1]), alpha = 1, lambda = 0.01)
pred_best_modelasso <- predict(best_modelasso, newx = as.matrix(db_final), s = 0.01)

write.csv(pred_best_modelasso, "l1-pred-J.csv")
```
  
